{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis Mathematics, Algorithms and Modeling\n",
    "\n",
    "# AI Powered Recipe Recommendation System \n",
    "\n",
    "### Team : Group 3\n",
    "| Student No  | First Name                  | Last Name     |\n",
    "|-------------|-----------------------------|---------------|\n",
    "| 9041129     | Nidhi                       | Ahir          |\n",
    "| 9016986     | Keerthi                     | Gonuguntla    |\n",
    "| 9027375     | Khushbu                     | Lad           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "\n",
    "This presentation is focused on the data cleaning techniques as per last class notes. It will mainly deal with data reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset & Programming Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ractangular Dataset : files\n",
    "1. Raw_recepes.csv\n",
    "2. Raw_interaction.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import scipy.stats as zscore\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['agg.path.chunksize'] = 10000\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RawRecipe : Dataset in classes and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawRecipe:\n",
    "    def __init__(self):\n",
    "        self.file_path = './Dataset/RAW_recipes.csv'\n",
    "        self.data = None\n",
    "    \n",
    "    # Loads the data from a CSV file.\n",
    "    def load_data(self):\n",
    "        self.data = pd.read_csv(self.file_path)\n",
    "        print(f\"---> STEP 1 : Loads the data from a CSV file. \\r\\n\")\n",
    "        print(f\"RAW_recipes.csv : Data loaded successfully.\")\n",
    "        print(f\"Total Records : {self.data.shape[0]} \\r\\n\")\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RAW_interactions : Dataset in classes and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecepeInteraction:\n",
    "    def __init__(self):\n",
    "        self.file_path = './Dataset/RAW_interactions.csv'\n",
    "        self.data = None\n",
    "    \n",
    "    # Loads the data from a CSV file.\n",
    "    def load_data(self):\n",
    "        self.data = pd.read_csv(self.file_path)\n",
    "        print(f\"---> STEP 1 : Loads the data from a CSV file. \\r\\n\")\n",
    "        print(f\"RAW_interactions.csv : Data loaded successfully.\")\n",
    "        print(f\"Total Records : {self.data.shape[0]} \\r\\n\")\n",
    "        return self.data\n",
    "    \n",
    "    def view_sample_data(self):\n",
    "        self.data.head(5)\n",
    "\n",
    "    # Data quality : Null Check\n",
    "    def check_null_values(self):\n",
    "        print(f\"---> STEP 2 : Null Check for data \\r\\n\")\n",
    "        if self.data is not None:\n",
    "            nulls = self.data.isnull().sum()\n",
    "            print(nulls)\n",
    "            return nulls\n",
    "        else:\n",
    "            print(\"Data not loaded.\")\n",
    "     # Data quality : Duplicate Check\n",
    "    def check_duplicate_values(self):\n",
    "        print(f\"\\r\\n---> STEP 3 : Duplicate data Check for recepe \\r\\n\")\n",
    "        if self.data is not None:\n",
    "            counts = self.data[\"recipe_id\"].value_counts()\n",
    "            dupl = (counts[counts>1]).reset_index()\n",
    "            dupl.columns = [\"recipe_id\", \"Count\"]\n",
    "            print(dupl)\n",
    "            return dupl\n",
    "        else:\n",
    "            print(\"Data not loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The main function : Initialise class objects & load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> STEP 1 : Loads the data from a CSV file. \n",
      "\n",
      "RAW_interactions.csv : Data loaded successfully.\n",
      "Total Records : 1132367 \n",
      "\n",
      "---> STEP 1 : Loads the data from a CSV file. \n",
      "\n",
      "RAW_recipes.csv : Data loaded successfully.\n",
      "Total Records : 231637 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Create an instance of the RecepeInteraction  class and load data\n",
    "    interactionData = RecepeInteraction()\n",
    "    interactionData.load_data()\n",
    "\n",
    "    # Create an instance of the RecepeInteraction  class and load data\n",
    "    recepeData = RawRecipe()\n",
    "    recepeData.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge dataset based on recepe Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Merged Successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>steps</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arriba   baked winter squash mexican style</td>\n",
       "      <td>137739</td>\n",
       "      <td>55</td>\n",
       "      <td>47892</td>\n",
       "      <td>2005-09-16</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>['make a choice and proceed with recipe', 'dep...</td>\n",
       "      <td>autumn is my favorite time of year to cook! th...</td>\n",
       "      <td>['winter squash', 'mexican seasoning', 'mixed ...</td>\n",
       "      <td>7</td>\n",
       "      <td>4470</td>\n",
       "      <td>137739</td>\n",
       "      <td>2006-02-18</td>\n",
       "      <td>5</td>\n",
       "      <td>I used an acorn squash and recipe#137681 Swee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arriba   baked winter squash mexican style</td>\n",
       "      <td>137739</td>\n",
       "      <td>55</td>\n",
       "      <td>47892</td>\n",
       "      <td>2005-09-16</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>['make a choice and proceed with recipe', 'dep...</td>\n",
       "      <td>autumn is my favorite time of year to cook! th...</td>\n",
       "      <td>['winter squash', 'mexican seasoning', 'mixed ...</td>\n",
       "      <td>7</td>\n",
       "      <td>593927</td>\n",
       "      <td>137739</td>\n",
       "      <td>2010-08-21</td>\n",
       "      <td>5</td>\n",
       "      <td>This was a nice change. I used butternut squas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name      id  minutes  \\\n",
       "0  arriba   baked winter squash mexican style  137739       55   \n",
       "1  arriba   baked winter squash mexican style  137739       55   \n",
       "\n",
       "   contributor_id   submitted  \\\n",
       "0           47892  2005-09-16   \n",
       "1           47892  2005-09-16   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "1  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "\n",
       "                               nutrition  n_steps  \\\n",
       "0  [51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]       11   \n",
       "1  [51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]       11   \n",
       "\n",
       "                                               steps  \\\n",
       "0  ['make a choice and proceed with recipe', 'dep...   \n",
       "1  ['make a choice and proceed with recipe', 'dep...   \n",
       "\n",
       "                                         description  \\\n",
       "0  autumn is my favorite time of year to cook! th...   \n",
       "1  autumn is my favorite time of year to cook! th...   \n",
       "\n",
       "                                         ingredients  n_ingredients  user_id  \\\n",
       "0  ['winter squash', 'mexican seasoning', 'mixed ...              7     4470   \n",
       "1  ['winter squash', 'mexican seasoning', 'mixed ...              7   593927   \n",
       "\n",
       "   recipe_id        date  rating  \\\n",
       "0     137739  2006-02-18       5   \n",
       "1     137739  2010-08-21       5   \n",
       "\n",
       "                                              review  \n",
       "0   I used an acorn squash and recipe#137681 Swee...  \n",
       "1  This was a nice change. I used butternut squas...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge data using common field recepe Id\n",
    "merged_data = pd.merge(recepeData.data, interactionData.data, left_on='id', right_on='recipe_id')\n",
    "print(\"Data Merged Successfully\")\n",
    "merged_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing value Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Ratio</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name</td>\n",
       "      <td>0.0000008831</td>\n",
       "      <td>0.0000883106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>minutes</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>contributor_id</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>submitted</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tags</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nutrition</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n_steps</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>steps</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>description</td>\n",
       "      <td>0.0207618202</td>\n",
       "      <td>2.0761820152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ingredients</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>n_ingredients</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>user_id</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>recipe_id</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>date</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rating</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>0.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>review</td>\n",
       "      <td>0.0001492449</td>\n",
       "      <td>0.0149244900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Column Name        Ratio   Percentage\n",
       "0             name 0.0000008831 0.0000883106\n",
       "1               id 0.0000000000 0.0000000000\n",
       "2          minutes 0.0000000000 0.0000000000\n",
       "3   contributor_id 0.0000000000 0.0000000000\n",
       "4        submitted 0.0000000000 0.0000000000\n",
       "5             tags 0.0000000000 0.0000000000\n",
       "6        nutrition 0.0000000000 0.0000000000\n",
       "7          n_steps 0.0000000000 0.0000000000\n",
       "8            steps 0.0000000000 0.0000000000\n",
       "9      description 0.0207618202 2.0761820152\n",
       "10     ingredients 0.0000000000 0.0000000000\n",
       "11   n_ingredients 0.0000000000 0.0000000000\n",
       "12         user_id 0.0000000000 0.0000000000\n",
       "13       recipe_id 0.0000000000 0.0000000000\n",
       "14            date 0.0000000000 0.0000000000\n",
       "15          rating 0.0000000000 0.0000000000\n",
       "16          review 0.0001492449 0.0149244900"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value_ratio = (merged_data.isnull().sum() / len(merged_data))\n",
    "missing_value_percentage = missing_value_ratio * 100\n",
    "pd.set_option('display.float_format', '{:.10f}'.format)\n",
    "\n",
    "missing_values_table = pd.DataFrame({\n",
    "    'Column Name': missing_value_ratio.index,\n",
    "    'Ratio': missing_value_ratio.values,\n",
    "    'Percentage': missing_value_percentage.values\n",
    "})\n",
    "missing_values_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data suggests that there are only null values in 3 columns name, description and review. Here, description and review is not a mandatory or important feature in the dataset. The \"name\" column must have value. We can drop records with null names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = merged_data.dropna(subset=['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low Variance Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                      17003803127.6721191406\n",
      "minutes              77378371288826.5937500000\n",
      "contributor_id     4589619737965439.0000000000\n",
      "n_steps                          33.8687988906\n",
      "n_ingredients                    13.6154322700\n",
      "user_id          251429104826142400.0000000000\n",
      "recipe_id               17003803127.6721191406\n",
      "rating                            1.5995814482\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "numerical_features = merged_data.select_dtypes(include=['number'])\n",
    "variance = numerical_features.var()\n",
    "print(variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Reviewing variance of all numerical features, features with variance > 100 are columns including ID's. \n",
    "2. number of steps and ingredients has considerable lower variance, however those columns contains values which can not be ignored to perform ML tasks.\n",
    "3. Rating is having lowest variance among all numerical features. However, Rating is integral part of data as it has categorical data between 1 to 5 numbers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High Correlation Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                id      minutes  contributor_id      n_steps  n_ingredients  \\\n",
      "id             NaN 0.0031643677    0.1029516836 0.0567002909   0.0181197736   \n",
      "minutes        NaN          NaN    0.0001325212 0.0004375931   0.0010589317   \n",
      "contributor_id NaN          NaN             NaN 0.0277206877   0.0053791485   \n",
      "n_steps        NaN          NaN             NaN          NaN   0.3802954944   \n",
      "n_ingredients  NaN          NaN             NaN          NaN            NaN   \n",
      "user_id        NaN          NaN             NaN          NaN            NaN   \n",
      "recipe_id      NaN          NaN             NaN          NaN            NaN   \n",
      "rating         NaN          NaN             NaN          NaN            NaN   \n",
      "\n",
      "                    user_id    recipe_id       rating  \n",
      "id             0.1000590419 1.0000000000 0.0135653999  \n",
      "minutes        0.0005947115 0.0031643677 0.0010534285  \n",
      "contributor_id 0.1027458073 0.1029516836 0.0122144900  \n",
      "n_steps        0.0516858362 0.0567002909 0.0211706262  \n",
      "n_ingredients  0.0081342176 0.0181197736 0.0035286409  \n",
      "user_id                 NaN 0.1000590419 0.1961822884  \n",
      "recipe_id               NaN          NaN 0.0135653999  \n",
      "rating                  NaN          NaN          NaN  \n",
      "Features to remove due to high correlation: ['recipe_id']\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = numerical_features.corr().abs()\n",
    "upper_triangle = correlation_matrix.where(\n",
    "    np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)\n",
    ")\n",
    "print(upper_triangle)\n",
    "\n",
    "threshold = 0.9\n",
    "highly_correlated = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n",
    "\n",
    "print(\"Features to remove due to high correlation:\", highly_correlated)\n",
    "\n",
    "df_filtered = merged_data.drop(columns=highly_correlated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal Component Analysis (PCA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio: [0.25726245 0.1719967 ]\n",
      "Principal Components:\n",
      "                   PC1           PC2\n",
      "0       -0.3247712722 -0.2419663842\n",
      "1       -0.3245840519 -0.2418344166\n",
      "2       -0.3247160209 -0.2419274387\n",
      "3       -1.2904069975 -0.1049440968\n",
      "4       -1.4926938349 -0.4891884359\n",
      "...               ...           ...\n",
      "1132361  1.4020954602 -0.8122966214\n",
      "1132362  1.5375237071  0.1228669409\n",
      "1132363  1.4096947961 -0.9129287057\n",
      "1132364  1.2480004672 -1.2202289191\n",
      "1132365  2.0226483570 -0.4325397473\n",
      "\n",
      "[1132366 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extracting only numeric columns for PCA\n",
    "numeric_data = merged_data.select_dtypes(include=[float, int])\n",
    "\n",
    "# Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(numeric_data)\n",
    "\n",
    "# Applying PCA, choosing 2 components as an example\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(data_scaled)\n",
    "\n",
    "# Creating a DataFrame with the principal components\n",
    "pca_data = pd.DataFrame(principal_components, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Displaying the explained variance and the transformed data\n",
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n",
    "print(\"Principal Components:\\n\", pca_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      " user_id          0.3792770853\n",
      "contributor_id   0.1524160286\n",
      "id               0.1005026234\n",
      "recipe_id        0.1004300101\n",
      "minutes          0.1004252063\n",
      "n_steps          0.0899135655\n",
      "n_ingredients    0.0770354808\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def random_forest_feature_importance(data, target_column='rating'):\n",
    "    \"\"\"\n",
    "    Use Random Forest to evaluate feature importance.\n",
    "    \"\"\"\n",
    "    # Selecting the features and target variable\n",
    "    X = data.select_dtypes(include=['number']).drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "\n",
    "    # Instantiate the RandomForestRegressor\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    # Get feature importances\n",
    "    feature_importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "    feature_importances_sorted = feature_importances.sort_values(ascending=False)\n",
    "    \n",
    "    print(\"Feature importances:\\n\", feature_importances_sorted)\n",
    "    return feature_importances_sorted\n",
    "\n",
    "# Apply Random Forest Feature Importance to the cleaned merged data\n",
    "feature_importances = random_forest_feature_importance(merged_data, target_column='rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward/Forward Feature Elimination/Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected after Backward Elimination: Index(['id', 'minutes', 'contributor_id', 'n_steps', 'n_ingredients',\n",
      "       'user_id', 'recipe_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def backward_elimination(data, target_column='rating', threshold=0.05):\n",
    "   \n",
    "    # Define the target and features\n",
    "    X = data.select_dtypes(include=['number']).drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Instantiate the RandomForestRegressor\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Get feature importances\n",
    "    feature_importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "    \n",
    "    # Backward Elimination: Remove features with low importance\n",
    "    while feature_importances.max() < threshold:\n",
    "        # Remove the least important feature\n",
    "        least_important_feature = feature_importances.idxmin()\n",
    "        X_train = X_train.drop(columns=[least_important_feature])\n",
    "        X_test = X_test.drop(columns=[least_important_feature])\n",
    "        \n",
    "        # Re-train the model\n",
    "        rf.fit(X_train, y_train)\n",
    "        feature_importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "    \n",
    "    print(f\"Features selected after Backward Elimination: {X_train.columns}\")\n",
    "    return X_train, X_test\n",
    "\n",
    "# Apply Backward Elimination\n",
    "X_train_selected, X_test_selected = backward_elimination(merged_data, target_column='rating')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvPROG8431",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
